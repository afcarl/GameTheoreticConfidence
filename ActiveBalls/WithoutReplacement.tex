\subsection{sampling without replacement}
Before proving Theorem~\ref{thm:Bias-Convergence} we prove a 
lemma regarding the concentration of sampling without replacement.

Let $a_1,\ldots,a_n$ be a fixed sequence where $a_i \in
\{0,1\}$. We denote the number of 1's by $k=\sum_{i=1}^n a_i$.

We compare sequentially sampling $0 \leq t \leq n$ times from $a_1^n$ with and
without replacement. We define $k_t$ for $0 \leq t \leq n$ to be the
random variable corresponding to the number of $1$'s sampled in the
first $t$ iterations.

We denote by $P_{ti}$ the probability that $k_t=i$ when sampling {\em
  with} replacement, and by $Q_{ti}$ the probability that $k_t=i$ when
sampling {\em without} replacement.

The probabilities $P_{ti}$ and $Q_{ti}$ obey the following inductions. 
The base case is $t=0$ and there $P_{00}=Q_{00}=1$ and for all $i\neq
0$ $P_{0i}=Q_{0i}=0$.

For $t>0$ the following recursions hold for all $i$:
\[
P_{t+1,i}=\frac{k}{n}P_{t,i-1} + \left(1-\frac{k}{n}\right)P_{t,i}
\]
and
\[
Q_{t+1,i}=\frac{k-i+1}{n-t}Q_{t,i-1} + \left(1-\frac{k-i}{n-t}\right)Q_{t,i}
\]

The mean of $k_t$ is the same whether the sampling is equal to
$E_t=E(k_t)=\frac{kt}{n}$ whether sampling with replacement or
not. For each $0\leq t \leq n$ we partition the range $0\leq i \leq t$
into the left part $L_t = \{1 | 0 \leq i <E_t \}$
and the right part $R_t=\{i | E_t < i \leq t\}$. (When
$E_t$ is an integer the mid-point $i=E_t$ is neither in $L_t$ nor in $R_t$).

The following lemma states that for any $0 \leq t \leq n$,
$P_{ti}$ and $Q_{ti}$ are non decreasing on the left part and non
increasing on the right part.
\begin{lemma}
  for all $0 \leq t \leq n$:
  \begin{itemize}
  \item For all $i< E_t$ (the left part), $P_{t,i-1} \leq P_{t,i}$ and
    $Q_{t,i-1} \leq Q_{t,i}$
  \item For all $i>E_t$ (the right part), $P_{t,i+1} \leq P_{t,i}$ and
    $Q_{t,i+1} \leq Q_{t,i}$
  \end{itemize}
\end{lemma}
\begin{proof}
  We prove the claim by induction:
  \begin{itemize}
    \item {\bf Base case:} for $t=0$, $E_t=0$, $P_{00}=Q_{00}=1$ and
      for all $i\neq 0$ $P_{0i}=Q_{0i}=0$ and the claim follows.
    \item {\bf Induction} Assume the claim holds for $t$ and prove for
      $t+1$. Consider $P_{t+1,i-1},P_{t+1,i}$ on the left
      part, i.e. $i < \frac{(t+1)k}{n}$. The recursion
      implies that $P_{t+1,i-1}$ is a convex combination of 
      $P_{t,i-2}$ and $P_{t,i-1}]$ and that $P_{t+1,i}$ is a convex
        combination of $P_{t,i-1}]$ and $P_{t,i}$. 
    \end{itemize}
\end{proof}

\newcommand{\Pupper}{{\mathbf P}^{R}}
\newcommand{\Plower}{{\mathbf P}^{L}}
\newcommand{\Qupper}{{\mathbf Q}^{R}}
\newcommand{\Qlower}{{\mathbf Q}^{L}}

We are interested in comparing the tail probabilities for the two
processes. For all $1 \leq t \leq n$ and $1 \leq i < \left\lfloor
E_t\right\rfloor $ we define the left tails as:
\[
\Plower_{ti} = \sum_{j=1}^i P_{tj},\;\;
\Qlower_{ti} = \sum_{j=1}^i Q_{tj}\;\;
\]
For $\lceil pi \rceil < j \leq i$ we define the upper tails to be
\[
\Pupper_{ij} = \sum_{j=i}^t P_{tj},\;\;
\Qupper_{ij} = \sum_{j=i}^t Q_{tj}\;\;
\]

Using this notation we can state the following lemma. Intuitively,
this lemma states that the distribution generated by sampling without
replacement is more concentrated around the mean than the
corresponding distribution for sampling with replacement.
\begin{lemma}
For all $1 \leq i \leq n$ and $1 \leq j < \lfloor pi \rfloor$,
$\Plower_{ij} > \Qlower_{ij}$, and for all $1 \leq i \leq n$, $\lceil
pi \rceil < j \leq i$, $\Pupper_{ij} > \Qupper_{ij}$.
\end{lemma}
\begin{proof}
  By Induction over $i$.
  \end{proof}
