\subsection{sampling without replacement}

% Transition probabilities
\newcommand{\p}{p}
\newcommand{\q}{q_{t,i}}

%$$\p=k/n$$
%$$\q=\frac{k-i}{n-t}$$

% RVs
\newcommand{\cnt}[2]{k^{#1}_{#2}}

%  bin probabilities
\newcommand{\prob}[2]{#1_{#2}}
%$\bin{P}{t,i}, \bin{Q}{t,i}$

% tail probabilities
\newcommand{\tail}[3]{{\mathbf #1}^{#2}_{#3}}

%$$\tail{L}{P}{t,i}$$


Before proving Theorem~\ref{thm:Bias-Convergence} we prove a 
lemma regarding the concentration of sampling without replacement.

Let $a_1,\ldots,a_n$ be a sequence where $a_i \in
\{0,1\}$. We denote the number of 1's by $k=\sum_{i=1}^n a_i$.

We compare sampling $n$ times from $a_1^n$ $n$ with and without
replacement. We denote by $\cnt{P}{t}$ the random variable
corresponding to the number of 1's after sampling $t$ times {\em with
  replacement}, and by $\cnt{Q}{t}$ the corresponding random
variable when the sampling is done {\em without replacement}.

We deonte the marginal probability that $\cnt{P}{t}=i$ by
$\prob{P}{t,i}$ and the probability that $\cnt{Q}{t}=i$ by
$\prob{Q}{t,i}$. For $t=0$ we have that 
$\prob{P}{0,0}=\prob{Q}{0,0}=1$ and for all $i\neq 0$
$\prob{P}{0,i}=\prob{Q}{0,i}=0$.
For $t \geq 0$ the following recursion holds:
\[
\prob{P}{t+1,i}=\frac{k}{n} \prob{P}{t,i-1} + \left(1-\frac{k}{n}\right)\prob{P}{t,i}
\]
and
\[
\prob{Q}{t+1,i}=\frac{k-i+1}{n-t}\prob{Q}{t,i-1} + \left(1-\frac{k-i}{n-t}\right)\prob{Q}{t,i-1}
\]

We denote the probability of sampling a 1 when sampling with
replacement by $\p=k/n$ and the probability of sampling a 1 when
sampling with replacement at step $t$ given that the number of 1's
sampled so far is $i$ by $\q=\frac{k-i}{n-t}$

Note that if $i < \p t$ then
\[
\q=\frac{k-i}{n-t} > \frac{k-\p t}{n-t} = \frac{k(1-t/n)}{n-t} =
\frac{k(n-t)}{n(n-t)} = \frac{k}{n}=\p,
\]
and if $i > \p t$ then
\[
\q=\frac{k-i}{n-t} < \frac{k-\p t}{n-t} = \frac{k}{n}=\p.
\]

For $0 \leq t \leq n$ and $0 \leq i \leq t$ we define the left and
right tails of the $P$ and $Q$ distributions as follows:
\[
\tail{L}{P}{t,i} \doteq \sum_{j=0}^i \prob{P}{t,j},\;\;\;\;\;\;
\tail{L}{Q}{t,i} \doteq \sum_{j=0}^i \prob{Q}{t,j}
\]
\[
\tail{R}{P}{t,i} \doteq \sum_{j=i}^t \prob{P}{t,j},\;\;\;\;\;\;
\tail{R}{Q}{t,i} \doteq \sum_{j=i}^t \prob{Q}{t,j}
\]
We can now state our main lemma regarding the tails of the
distribution $Q$.
\begin{lemma}
  For all $0\leq t \leq n$
  \begin{itemize}
    \item If $i < \lfloor \p t \rfloor$ then $\tail{L}{Q}{t,i} < \tail{L}{P}{t,i}$
    \item If $i > \lceil \p t \rceil$ then $\tail{R}{Q}{t,i} < \tail{R}{P}{t,i}$
    \end{itemize}
\end{lemma}

\iffalse
The mean of $k_t$ is the same whether the sampling is equal to
$E_t=E(k_t)=\frac{kt}{n}$ whether sampling with replacement or
not. For each $0\leq t \leq n$ we partition the range $0\leq i \leq t$
into the left part $L_t = \{1 | 0 \leq i <E_t \}$
and the right part $R_t=\{i | E_t < i \leq t\}$. (When
$E_t$ is an integer the mid-point $i=E_t$ is neither in $L_t$ nor in $R_t$).

The following lemma states that for any $0 \leq t \leq n$,
$P_{ti}$ and $Q_{ti}$ are non decreasing on the left part and non
increasing on the right part.
\begin{lemma}
  for all $0 \leq t \leq n$:
  \begin{itemize}
  \item For all $i< E_t$ (the left part), $P_{t,i-1} \leq P_{t,i}$ and
    $Q_{t,i-1} \leq Q_{t,i}$
  \item For all $i>E_t$ (the right part), $P_{t,i+1} \leq P_{t,i}$ and
    $Q_{t,i+1} \leq Q_{t,i}$
  \end{itemize}
\end{lemma}
\begin{proof}
  We prove the claim by induction:
  \begin{itemize}
    \item {\bf Base case:} for $t=0$, $E_t=0$, $P_{00}=Q_{00}=1$ and
      for all $i\neq 0$ $P_{0i}=Q_{0i}=0$ and the claim follows.
    \item {\bf Induction} Assume the claim holds for $t$ and prove for
      $t+1$. Consider $P_{t+1,i-1},P_{t+1,i}$ on the left
      part, i.e. $i < \frac{(t+1)k}{n}$. The recursion
      implies that $P_{t+1,i-1}$ is a convex combination of 
      $P_{t,i-2}$ and $P_{t,i-1}]$ and that $P_{t+1,i}$ is a convex
        combination of $P_{t,i-1}]$ and $P_{t,i}$. 
    \end{itemize}
\end{proof}


We are interested in comparing the tail probabilities for the two
processes. For all $1 \leq t \leq n$ and $1 \leq i < \left\lfloor
E_t\right\rfloor $ we define the left tails as:
\[
\Plower_{ti} = \sum_{j=1}^i P_{tj},\;\;
\Qlower_{ti} = \sum_{j=1}^i Q_{tj}\;\;
\]
For $\lceil pi \rceil < j \leq i$ we define the upper tails to be
\[
\Pupper_{ij} = \sum_{j=i}^t P_{tj},\;\;
\Qupper_{ij} = \sum_{j=i}^t Q_{tj}\;\;
\]

Using this notation we can state the following lemma. Intuitively,
this lemma states that the distribution generated by sampling without
replacement is more concentrated around the mean than the
corresponding distribution for sampling with replacement.
\begin{lemma}
For all $1 \leq i \leq n$ and $1 \leq j < \lfloor pi \rfloor$,
$\Plower_{ij} > \Qlower_{ij}$, and for all $1 \leq i \leq n$, $\lceil
pi \rceil < j \leq i$, $\Pupper_{ij} > \Qupper_{ij}$.
\end{lemma}
\begin{proof}
  By Induction over $i$.
  \end{proof}
\fi
