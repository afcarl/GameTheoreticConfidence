\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{color}

\usepackage{hyperref}
\usepackage{url}
\usepackage{times}
\usepackage[algo2e]{algorithm2e}

%\usepackage{fullpage}
%\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{bbm}
\usepackage{graphics, graphicx, xcolor}
\usepackage{enumitem}
%\usepackage{verbatim}		% for misc commenting, etc.
\usepackage{stmaryrd}
\usepackage{float}
\usepackage[mathscr]{euscript}


\usepackage{geometry}
%% \geometry{a4paper,
%%   total={170mm,220mm},
%%   marginparwidth=80mm,
%% left=5mm,
%% right=85mm,
%% top=20mm,
%% }

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}


\title{Non-Parametric Active Learning}
\author{Akshay Balsubramani, Yoav Freund, Shay Moran}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{assumption}[theorem]{assumption}
\newtheorem{definition}[theorem]{Definition}

\newtheorem{thm}{Theorem}%[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{obs}[thm]{Observation}
\newtheorem{defn}[thm]{Definition}
\newtheorem{alg}{Algorithm}
\newtheorem{ass}{Assumption}
\newtheorem{examp}{Example}
\newtheorem{property}{Property}
\setcounter{MaxMatrixCols}{20}

\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Prtxt}{Pr}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\polylog}{polylog}

\newcommand{\err}{\mbox{err}}
\newcommand{\X}{{\cal X}}
\newcommand{\Y}{{\cal Y}}
\newcommand{\D}{{\cal D}}
\newcommand{\B}{{\cal B}}
\newcommand{\x}{\vec{x}}
\newcommand{\y}{\vec{y}}
\newcommand{\vv}{\vec{v}}
\newcommand{\cc}{\vec{c}}

\newcommand{\K}{{\cal K}}
\newcommand{\restrictedto}{\triangleright}
\renewcommand{\SS}{{\cal S}} % Specialists
\newcommand{\CC}{{\cal C}}  % constraints

\newcommand{\outcome}{z}
\newcommand{\empoutcome}{\hat{\outcome}}
\newcommand{\polarity}{p}

\newcommand{\bd}[1]{\mathbf{#1}}  % for bolding symbols
\newcommand{\RR}{\mathbb{R}}      % Real numbers
\newcommand{\ZZ}{\mathbb{Z}}      % Integers
\newcommand{\NN}{\mathbb{N}}      % natural numbers
\newcommand{\RP}{\mathbb{RP}}      % real projective space
\newcommand{\Sp}{\mathbb{S}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\col}[1]{\left[\begin{matrix} #1 \end{matrix} \right]}
\newcommand{\comb}[2]{\binom{#1^2 + #2^2}{#1+#2}}
\newcommand{\vnorm}[1]{\left\lVert#1\right\rVert} % vector norm
\newcommand{\bfloor}[1]{\left\lfloor#1\right\rfloor} % floor function
\newcommand{\bceil}[1]{\left\lceil#1\right\rceil} % ceiling function
\newcommand{\ifn}{\mathbf{1}} % indicator function for sets
\newcommand{\EV}{\mathbb{E}} % expected value operator
\newcommand{\evp}[2]{\mathbb{E}_{#2} \left[#1\right]} % expected value operator
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\pr}[1]{\Prtxt \left(#1\right)}
\newcommand{\prp}[2]{\Prtxt_{#2} \left(#1\right)}
\newcommand{\ip}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\emperr}[2]{\widehat{\mbox{err}}_{#2} \left(#1\right)}

\newcommand{\pdis}[1]{P_{dis}\left(#1\right)}
\newcommand{\lrp}[1]{\left(#1\right)}
\newcommand{\lrb}[1]{\left[#1\right]}
\newcommand{\lrsetb}[1]{\left\{#1\right\}}

\newcommand{\corr}{\mbox{corr}}
\newcommand{\ones}[1]{\mathbbm{1}^{#1}}
\newcommand{\vA}{\mathbf{A}}
\newcommand{\va}{\mathbf{a}}
\newcommand{\vd}{\mathbf{d}} 
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vF}{\mathbf{F}} 
\newcommand{\vI}{\mathbf{I}}  
\newcommand{\vh}{\mathbf{h}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vb}{\mathbf{b}} 
\newcommand{\vu}{\mathbf{u}}   
\newcommand{\vl}{\mathbf{l}}
\newcommand{\vm}{\mathbf{m}}    
\newcommand{\vg}{\mathbf{g}}   
\newcommand{\vp}{\mathbf{p}}
\newcommand{\vq}{\mathbf{q}}
\newcommand{\vr}{\mathbf{r}}
\newcommand{\vs}{\mathbf{s}}
\newcommand{\vt}{\mathbf{t}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\valpha}{\vec{\alpha}}
\newcommand{\vbeta}{\vec{\beta}}
\newcommand{\vzero}{\mathbf{0}}
\newcommand{\vone}{\mathbf{1}}

\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cZ}{\mathcal{Z}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cO}{\mathcal{O}}

\newcommand{\bias}{\text{bias}}
\newcommand{\ebias}{\widehat{\text{bias}}}

\newcommand{\eD}{\hat{\D}}
\newcommand{\ep}{\hat{p}}

\newcommand{\samp}{S}
\newcommand{\usamp}{\underline{S}}

\newcommand{\eps}{\epsilon}

\newcommand{\sign}{\text{sign}}
\newcommand{\new}[1]{\textcolor{red}{#1}}

\newcommand{\comment}[3]{\marginpar{\textcolor{#2}{#1: #3}}}
%\newcommand{\comment}[3]{}
\newcommand{\shay}[1]{\comment{Shay}{red}{#1}}
\newcommand{\yoav}[1]{\comment{Yoav}{blue}{#1}}
\newcommand{\akshay}[1]{\comment{Akshay}{magenta}{#1}}

\begin{document}

\maketitle
\section{Introduction}

The analysis of Active Learning using Muffler seems to run into a dead
end. Specifically, the elegant local condition we call ``Pairwise
safe'' is insufficient to guarantee version space consistency.

In this paper we suggest a different approach to the problem of active
learning using balls. Instead of using the min/max solution given by
Muffler, we consider an Occam's razor approach by which we make the
simplest prediction possible given the constraints.

\section{Ball Specialists}

We restrict our attention to a special case which corresponds,
roughly, to nearest neighbor methods.
\begin{enumerate}
\item The input space $\X$ is a finite set in $R^d$. We assume a
  uniform distribution over $\X$.
  \item We consider labels $y\in \{-1,+1\}$. For There is a fixed but
    unknown conditional probability defined over $\X$, i.e. $P(Y=+1 |
    X=\x)$. Our goal is to estimate whether $P(Y=+1|X=\x)$ is smaller
    or larger than $1/2$.
  \item
    The notation is simpler if we use expected values instead of
    probabilities. We use the term {\em bias} of a ball to refer to the conditional
    expectation of the label for a ball by
    \[
    \bias(\x) \doteq P(Y=+1|X=\x) - P(Y=-1|X=\x)
    \]
  \item
    The rules that we use are ``specialists'' that are balls. The set
    $\B$ contains all rules of the form
    \[
    B_{r,\cc,s}(\x) =
    \begin{cases}
      s & \text{if } \| \cc- \x \| \leq r \\
    0 & \text{otherwise }
    \end{cases}
    \]
    Where $r \geq 0$ is the radius of the ball, $\cc \in R^d$ is the
    center of the ball and $s \in \{-1,+1\}$ is the polarity of the ball.
    We will drop the subscripts of $B$ when clear from context.
  \item
    We use $\x \in B$ to indicate that $B(\x) \neq 0$.
  \item
    We denote the {\em probability} of a ball $B$ by $p(B) \doteq
    \frac{|B|}{|\X|}$.
  \item
    We define term {\em bias} of a ball to refer to the conditional
    expectation of the label for a ball by
    \[
    \bias(B) \doteq E\left( y|\x \in B \right).
    \]
  \item We define a sample $\samp$ as a sequence of labeled examples:
    \[\samp= \left\langle (\x_1,y_1),(\x_2,y_2),\ldots,(\x_m,y_m)
    \right\rangle \]
    Where $\x_i$ are chosen uniformly at random (with replacement)
    from $\X$ and $y_i$ are chosen according to the (unknown)
    conditional distribution of the label given $\x$.
  \item Given a sample $\samp$, we define the number of instances in
    $(\x,y) \in \samp$ such that $\x \in B$ to be the {\em size} of
    $B$ according to the sample $\samp$ and denote it by $k_{\samp}$. We define
    the {\em empirical probability} of the ball $B$ according to
    $\samp$ by $p_{\samp}(B) \doteq k_{\samp}(B)/|\samp|$.
  \item Given a sample $\samp$ we define the estimate of the
    $\bias(B)$ to be
    \[
    \ebias_{\samp}(B) = \frac{\sum_{i=1}^m y_i B(\x_i)}{\sum_{i=1}^m B(\x_i)}
    \]
  \item Using uniform convergence bounds we define for each ball $B$
    a confidence interval:
    $[l,h]=[\ebias(B)-\Delta,\ebias(B)+\Delta]$.
    if $l>0$ we say that $B$ imposes a {\em positive constraint}, if
    $h<0$ we say that $B$ imposes a {\em negative constraint}, i
    $l\leq 0 \leq h$ we say that $B$ does not impose a constraint.
\end{enumerate}

\section{Uniform convergence bounds for sepcialists.}
\subsection{Uniform convergence of measures}

In order for our unifom convergence bounds to hold, we need to remove
from consideration all balls in which the number of points is smaller
than some minimum $O(d \log n + \ln 1/\delta)$. As this threshold is
used in the algorithm we need to be specific and we choose
$2k_0=6\left[  d \log n + \log(1/\delta) \right]$ to be the threshold.

It might be the case that by properly chosing the length of the
confidence interval we can make sure that when $k(ball)<2k_0$ the
inteval would make the statement vacuous. Restricting $k(B)>2k_0$
gives a more direct proof. The bound is still better than the uniform
bound that depends on $n$ rather than on $k(B)$.

The first thing we show is that when using a sample of size $2n$, the
probability that there exists a ball $B$ such that $k_1(B)>2k_0$ and
$k_2(b)<k_0/2$ is smaller than $\delta$. In other words, the
probability that at least one of the balls used by the algorithm has
$k_2(B)<k_0/2$ is at most $\delta$.

%\begin{theorem}\label{thm:uc1}
%Let $\B$ be a family of specialists of VC dimension $d$,
%let $\delta>0$ and set $k_0=3\left[  d \log n + \log(1/\delta) \right]$
%and let $S_1,S_2$ be two independent samples $\bigl((x_i,y_i)\bigr) \sim p^n$. Then:
%\[\Pr_{\samp_1,\samp_2 \sim p^{2n}}\Bigl[\exists {B\in\B}:
%  k_{\samp_1}(B)>2k_0 \mbox{ and } k_{\samp_2}(B) < \frac{k_0}{2} \Bigr] \leq \delta
%\]
%\end{theorem}

\begin{theorem}\label{thm:uc1}
Let $\B$ be a family of specialists of VC dimension $d$,
let $\delta>0$ and set $k_0=3\left[  d \log n + \log(1/\delta) \right]$
and let $S$ be an independent sample $\bigl((x_i,y_i)\bigr) \sim p^n$. Then:
\[\Pr_{\samp \sim p^{n}}\Bigl[\exists {B\in\B}:
  p_{\samp}(B)>2k_0/n \mbox{ and } p(B) < k_0/n \Bigr] \leq \delta,
\]
and
\[\Pr_{\samp \sim p^{n}}\Bigl[\exists {B\in\B}:
  p_{\samp}(B)< 2k_0/n \mbox{ and } p(B) > 4k_0/n \Bigr] \leq \delta.
\]
\end{theorem}



Note that this has a meaning for the algorithm. It means that balls
that contain less than $2k_0$ points are ignored.

\begin{proof}
Sketch of proof. We use the standard uniform convergence bound with
the difference that We use the multiplicative Chernoff bound instead
 of the additive Hoeffding bound. 

We begin with the first inequality.  
We follow the double sampling argument.
Consider a double sample $S=(\samp_1,\samp_2)\sim p^{2n}$.
Let $E_1$ denote the event whose probability we want to bound:
\[
E_1 = \text{"}\exists {B\in\B}:
  p_{\samp_1}(B)>2k_0/n \mbox{ and } p(B) < k_0/n
\text{"}, 
\]
and let $E_2$ denote the event:
\[
E_1 = \text{"}\exists {B\in\B}:
  p_{\samp_1}(B)>2k_0/n \mbox{ and } p_{\samp_2}(B) < 1.5k_0/n
\text{"}.
\]
The proof follows from the following two lemmas:
\begin{lemma}\label{lem:aux1}
\[\Pr[E_1]\leq 4\Pr[E_2]\]
\end{lemma}
\begin{lemma}
\[\Pr[E_2]\leq \delta\]
\end{lemma}

  
  
%
%  Fix $B$, we have two cases: either $p(B) \leq k_0/n$ or
%  $p(B)>k_0/n$. We bound the probability of each case using chernoff:
%  \begin{itemize}
%  \item $p(B) \leq k_0/n$ then
%  \[
%  P\left[ k_{\samp_1}(B) \geq 2 k_0 \right] \leq \exp(-k_0/3)
%  \]
%  \item $p(B) > k_0/n$ then
%  \[
%  P\left[ k_{\samp_2}(B) < k_0/2 \right] \leq \exp(-k_0/2)
%  \]
%  \end{itemize}
%
%  We use the standard ghost sample argument to get a uniform bound
%  over all $B$ and choose $k_0$ so that the bad probability is bound by $\delta$.

  \end{proof}

\subsection{Uniform convergence of biases}
\begin{theorem}
Let $\B$ be a family of specialists of VC dimension $d$, 
let $\eps,\delta>0$,
and let $S=\bigl((x_i,y_i)\bigr) \sim p^n$.
Then:
\[\Pr_{\samp\sim p^n}\left[\exists {B\in\B}:~\lvert
  \bias_{\samp}(B) -  \bias(B)\rvert \geq \sqrt{\frac{100d\log n +
      \log(1/\delta)}{k(B)} }
  \mbox{ and } k(B)>2k_0
  \right] \leq \delta,
%\binom{n}{\leq d}\exp\bigl(-2\eps^2n\bigr),
\]
where $k(B) = \lvert\{ i : x_i\in B \}\rvert$.
%Then, the event:
%?For every specialist S: the absolute difference between its empirical bias and its true bias of S is at most sqrt{ (10d log n + log (1/delta) )/ k }?
%has probability at most delta.
\end{theorem}

\begin{proof}
We follow the double sampling argument.
Consider a double sample $S=(\samp_1,\samp_2)\sim p^{2n}$.
Let $E_1$ denote the event whose probability we want to bound:
\[
E_1 = \text{"}\exists {B\in\B}:~\lvert \bias_{\samp_1}(B) -
\bias(B)\rvert \geq \sqrt{\frac{100d\log n + \log(1/\delta)}{k_1(B)}}
\mbox{ and } k_1(B)>2k_0
\text{"}, 
\]
and let $E_2$ denote the event:
\[
E_2 = \text{"}\exists {B\in\B}:~\lvert \bias_{\samp_1}(B) -  \bias_{\samp_2}(B)\rvert \geq \sqrt{\frac{100d\log n + \log(1/\delta)}{k_1(B)}}
  \mbox{ and }~ \bigl(k_1(B) + k_2(B)\bigr)>2k_0
  \text{"},
\]
where $k_i(b)$ is the number of examples in $S_i$ that belong to $B$.
The proof follows from the following two lemmas:
\begin{lemma}\label{lem:aux1}
\[\Pr[E_1]\leq 4\Pr[E_2]\]
\end{lemma}
\begin{lemma}\label{lem:aux2}
\[\Pr[E_2]\leq \delta\]
\end{lemma}

\begin{proof}[Proof of Lemma~\ref{lem:aux1}.]

It suffices to show that $\Pr[E_2 \vert E_1]\geq 1/4$.
Indeed, this would imply that $\Pr[E_2 \vert E_1]\geq 1/4$, 
namely that $\Pr[E_1] \leq 4\Pr[E_1 \land E_2]\leq 4\Pr[E_2]$.

Let $S_1\in E_1$. Since $S_2$ and $S_1$ are independent,
it suffices to show that 
\[\Pr_{S_2\sim p^n}\bigl[(S_1,S_2)\in E_2\bigr] \geq 1/4.\]
Let $B\in\B$ such that $\lvert \bias_{\samp_1}(B) -  \bias(B)\rvert \geq \sqrt{\frac{100d\log n + \log(1/\delta)}{k_1(B)} }$
and $k_1(B) > 2k_0$. 
By Theorem~\ref{thm:uc1} we may assume (with probability $1-\delta$)
that~$p(B)\geq k_0/n$.

\paragraph{High level.} $p(B)\geq k_0/n$ implies that $k_2(B)$ is sufficiently large with probability at least 1/2,
say at least $k_0/100$.
This should imply that the $\bias_{\samp_2}(B)$ is sufficiently close
to $\bias(B)$, say to an additive factor of $\sqrt{\frac{100d\log n + \log(1/\delta)}{k_2(B)}}$.
Consequently, this should imply that $\bias_{\samp_2}(B)$ and $\bias_{\samp_1}(B)$
are at least some $\Omega(\sqrt{\frac{d\log n + \log(1/\delta)}{k_1(B)}})$ with a constant probability,
which is qualitatively $E_1$. To conclude, conditioned on $E_2$, the probability of $E_1$
is at least a constant.
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lem:aux2}]\ \\
\paragraph{High level.}
Instead of sampling $S_1$ and then $S_2$,
we first sample $S=S_1\cup S_2$ and 
then partition it to $S_1$ and $S_2$ uniformly.
Now, given a sample $S$ what is the probability (over the random partition)
that $E_2$ occurs?
First, we only need to worry about $B$'s such that $k_S(B) > 2k_0$.
For such a $B$, the probability that the biases differ should be sufficiently
small such that when we union bound over all $O(n^d)$ different $B$'s
we still get that the resulting probability is at most $\delta$.

\end{proof}

%We distinguish between two cases: $p(B)$ is large and $p(B)$ is small.
%The case when $p(B)$ is sufficiently large (at least $1/n$) is fine (I think).
%
%On the other hand, if $p(B)<k_0/n$ then, with hight probability
%$k_1(B)<2k_0$ and the ball will be eliminated from consideration.

\iffalse
Further assume that $\bias(B) = 0.8$,  that $\bias_{\samp_1}(B)=0$, and that $k_1(B)$
is sufficiently large so the $\lvert \bias_{\samp_1}(B) -  \bias(B)\rvert \geq \sqrt{\frac{100d\log n + \log(1/\delta)}{k_1(B)} }$.
Now, since $p(B) \leq 1/1000n$ it follows that $k_2(B)=0$ with probability at least $0.99$.
Now, it is plausible to define $\bias_{\samp_2}(B)=0$ when $k_2(B)=0$,
and therefore we get that $\bias_{\samp_2}=\bias_{\samp_1}=0$ with probability at least $0.99$ and so the event $E_2$ occurs with probability less than $0.01$,
unlike what we wanted.
\fi
\end{proof}

\section{The algoithm}

\subsection{Defining safe sets}

Given a set of constraints, and given a polarity  $s \in
\{-1,+1\}$ we define a point $\x$ as a $s$-safe if
the following holds
\begin{itemize}
\item There is an $s$ constraint that contains $\x$.
\item For any $-s$ constraint $C$ that contains $\x$, there exists an
  $s$ constraint $D$ such that $D \subset C$. 
\end{itemize}

Points that are neither positive nor negative safe are called
``unsafe''

\subsection{Active Learning}

At each stage of Active Learning we query the label of two sets, each
of size $n$
\begin{itemize}
\item {\bf Uniform Set :} select points uniformly at random from the whole
  domain.
\item {\bf Active Set :} select points uniformaly at random from the unsafe
  set.
\end{itemize}

The Uniform sets from different stages are combined to form one
large label set. The active set from each stage is considered
separately.

The bias of each constraint is calculated with respect to the
cumulative uniform sample, and with respect to each one of the active
sets. Each of these sets defines a contraint on a subset of the $z_i$'s 

\section{Sufficient conditions on the true bias}
\newcommand{\Bayes}{f^*}
The goal of our algorithm is to generate a rule $f$ that
approximates the Bayes decision rule $\Bayes(\x) = \sign(\bias(\x))$.
Specifically, we set our goal to be minimizing the regret $\err(f) - \err(\Bayes)$.

In this section we define conditions on $\bias(x)$ that guarantee that
the algorithm will achieve a regret of $\epsilon$ after querying the
labels of $O(\log 1/\epsilon)$ instances.

We do this in two steps. First, we describe a technical condition on
$\bias(\x)$. Second, we give two more natural conditions that
guarantee the technical condition.

\subsection{$\epsilon$ approximation using Balls}

Let $\D$ be the distribution over $\X\times \{-1,+1\}$ where the
distribution over $\X$ is uniform and the conditional distribution
over the label $y$ given $\x$ is define by $\bias(\x)$.

\newcommand{\Be}{{\cal B}_{\epsilon}}
\newcommand{\fBe}{f_{\Be}}
\newcommand{\UBe}{U_{\epsilon}}
We say that $\D$ is $\epsilon$ approximable using balls for $\epsilon>0$ if
there exists a collection of balls $\Be$ such that 
\begin{itemize}
\item For all $B \in \Be$, $P_{\D}(B)>\epsilon$
\item For all $B \in \Be$, $|\bias(B)-1/2| > \epsilon$
\item For all $B \in \Be$ and for any point $\x \in B$, $\sign(\bias(\x))=\sign(\bias(B))$
\item %Let $\UBe$ be the union of all of the balls in $\Be$, i.e. $\UBe
  %\doteq \bigcup_{B \in \Be} B$\\
  Define the prediction function $\fBe$ as follows:
  \[
  \fBe(\x) \doteq \begin{cases}
    1 & \exists B \in \Be, \;\;\mbox{such that}\;\; \x \in B,
    \bias(B)>0 \\
    0 & \nexists B \in \Be \;\;\mbox{such that}\;\; \x \in B \\
    -1 & \exists B \in \Be, \;\;\mbox{such that}\;\; \x \in B,
    \bias(B)<0
  \end{cases}
  \]
  The final requirement is that $\err(\fBe) \leq \err(\Bayes)+\epsilon$
\end{itemize}

\subsection{Specific conditions}

I believe either of the following conditions implies
$\epsilon$-approximation using balls.

\begin{enumerate}
\item
  {\bf The conditional probability is Lipshitz smooth}. In other words, for
any $\x,\y \in \X$:
\[
|\bias(\x) - \bias(\y)| \leq \alpha \|\x-\y\|_2^{\beta}
\]
\item
The bias is bounded away from zero and {\bf the boundary is low
dimensional}. More technically:
\begin{itemize}
\item There exists some $\epsilon_0$ such that $\forall \x \in \X$, $|\bias(\x)|>\epsilon_0$.
\item Recall that $\X \subset R^d$. Define boundary balls as balls
  that contain and element with positive bias and an element with
  negative bias. Let $G_{\epsilon}$ be the union of all boundary balls
  with probability at most $\epsilon$. We say that the boundary has
  low dimension if $P_{\D}(G_{\epsilon}) \to 0$ as $\epsilon \to 0$
  (one has to be a bit careful in the definition here because $\X$ is finite, so
  $G_{1/2|\X|}=\emptyset$ trivially).  
\end{itemize}
\end{enumerate}

\end{document}
